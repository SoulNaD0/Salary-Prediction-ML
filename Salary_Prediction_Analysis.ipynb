{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Prediction Analysis\n",
    "\n",
    "## Introduction\n",
    "This project aims to predict salaries based on various features such as age, education level, years of experience, country, race, and job title. The dataset used is `Salary_Data_Based_country_and_race.csv`, which contains salary information along with demographic and employment details.\n",
    "\n",
    "### Objectives:\n",
    "- Perform data cleaning and preprocessing.\n",
    "- Explore the dataset to understand the distribution of features.\n",
    "- Build and evaluate different regression models to predict salaries.\n",
    "- Identify the best-performing model for salary prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_raw = pd.read_csv('Salary_Data_Based_country_and_race.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data_raw.info()\n",
    "\n",
    "# Check for duplicates and missing values\n",
    "print(\"Number of duplicates:\", data_raw.duplicated().sum())\n",
    "print(\"Missing values per column:\\n\", data_raw.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and handle missing values\n",
    "data_raw.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "data_raw.dropna(inplace=True)\n",
    "\n",
    "# Display unique values for categorical columns\n",
    "print(\"Unique Genders:\", data_raw['Gender'].unique())\n",
    "print(\"Unique Education Levels:\", data_raw['Education Level'].unique())\n",
    "print(\"Unique Countries:\", data_raw['Country'].unique())\n",
    "print(\"Unique Races:\", data_raw['Race'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset for preprocessing\n",
    "df = data_raw.copy()\n",
    "\n",
    "# Map categorical variables to their frequency\n",
    "df['Gender'] = df['Gender'].map(df['Gender'].value_counts())\n",
    "df['Race'] = df['Race'].map(df['Race'].value_counts())\n",
    "\n",
    "# Map job titles and countries to their mean salary\n",
    "df['Job Title'] = df['Job Title'].map(df.groupby('Job Title')['Salary'].mean())\n",
    "df['Country'] = df['Country'].map(df.groupby('Country')['Salary'].mean())\n",
    "\n",
    "# Drop the original salary column\n",
    "df.drop(columns='Salary', inplace=True)\n",
    "\n",
    "# Standardize education levels\n",
    "df['Education Level'] = df['Education Level'].replace({\n",
    "    \"Bachelor's\": \"Bachelor\",\n",
    "    \"Bachelor's Degree\": \"Bachelor\",\n",
    "    \"Master's\": \"Master\",\n",
    "    \"Master's Degree\": \"Master\",\n",
    "    \"phD\": \"PhD\",\n",
    "    \"PhD\": \"PhD\"\n",
    "})\n",
    "\n",
    "# Map education levels to numerical values\n",
    "education_mapping = {\n",
    "    \"High School\": 0,\n",
    "    \"Bachelor\": 1,\n",
    "    \"Master\": 2,\n",
    "    \"PhD\": 3\n",
    "}\n",
    "df['Education Level'] = df['Education Level'].map(education_mapping)\n",
    "\n",
    "# Display the preprocessed dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical data distribution\n",
    "numerical_data = df[['Age', 'Years of Experience']]\n",
    "plt.boxplot(numerical_data)\n",
    "plt.title('Boxplot of Age and Years of Experience')\n",
    "plt.show()\n",
    "\n",
    "# Visualize salary distribution\n",
    "plt.boxplot(data_raw['Salary'])\n",
    "plt.title('Boxplot of Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x = df.values\n",
    "y = data_raw['Salary'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=444)\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_scaled, y_train)\n",
    "y_pred_test = lr.predict(x_test_scaled)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f'Linear Regression - Test RMSE: {test_rmse}, Test R²: {test_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "degrees = [1, 2, 3, 4, 5]\n",
    "train_errors, test_errors, train_r2_scores, test_r2_scores = [], [], [], []\n",
    "\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly.fit_transform(x_train_scaled)\n",
    "    x_test_poly = poly.transform(x_test_scaled)\n",
    "    lr.fit(x_train_poly, y_train)\n",
    "    y_pred_test_poly = lr.predict(x_test_poly)\n",
    "    test_rmse_poly = np.sqrt(mean_squared_error(y_test, y_pred_test_poly))\n",
    "    test_r2_poly = r2_score(y_test, y_pred_test_poly)\n",
    "    train_errors.append(test_rmse_poly)\n",
    "    test_errors.append(test_rmse_poly)\n",
    "    train_r2_scores.append(test_r2_poly)\n",
    "    test_r2_scores.append(test_r2_poly)\n",
    "\n",
    "best_degree = degrees[np.argmin(test_errors)]\n",
    "print(f'Best degree for Polynomial Regression: {best_degree}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Regression\n",
    "knr = KNeighborsRegressor()\n",
    "params = {\n",
    "    'n_neighbors': range(5, 21, 2),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "gclf = GridSearchCV(knr, param_grid=params, cv=10, scoring='neg_mean_squared_error')\n",
    "gclf.fit(x_train_scaled, y_train)\n",
    "best_knr_model = gclf.best_estimator_\n",
    "y_pred_test_knr = best_knr_model.predict(x_test_scaled)\n",
    "test_rmse_knr = np.sqrt(mean_squared_error(y_test, y_pred_test_knr))\n",
    "test_r2_knr = r2_score(y_test, y_pred_test_knr)\n",
    "print(f'KNN Regression - Test RMSE: {test_rmse_knr}, Test R²: {test_r2_knr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "rfr = RandomForestRegressor()\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 15, None],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['squared_error'],\n",
    "    'max_leaf_nodes': [10, None],\n",
    "    'min_samples_split': [10, 15],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "rfclf = GridSearchCV(rfr, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "rfclf.fit(x_train_scaled, y_train)\n",
    "best_rfr_model = rfclf.best_estimator_\n",
    "y_pred_test_rfr = best_rfr_model.predict(x_test_scaled)\n",
    "test_rmse_rfr = np.sqrt(mean_squared_error(y_test, y_pred_test_rfr))\n",
    "test_r2_rfr = r2_score(y_test, y_pred_test_rfr)\n",
    "print(f'Random Forest Regression - Test RMSE: {test_rmse_rfr}, Test R²: {test_r2_rfr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression\n",
    "svr = SVR()\n",
    "params_svr = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['poly', 'rbf'],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'epsilon': [0.01, 0.1, 0.5, 1, 5]\n",
    "}\n",
    "svgrid = RandomizedSearchCV(svr, param_distributions=params_svr, cv=5, n_iter=5, scoring='neg_mean_squared_error')\n",
    "svgrid.fit(x_train_scaled, y_train)\n",
    "best_svr_model = svgrid.best_estimator_\n",
    "y_pred_test_svr = best_svr_model.predict(x_test_scaled)\n",
    "test_rmse_svr = np.sqrt(mean_squared_error(y_test, y_pred_test_svr))\n",
    "test_r2_svr = r2_score(y_test, y_pred_test_svr)\n",
    "print(f'SVR - Test RMSE: {test_rmse_svr}, Test R²: {test_r2_svr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "results = {\n",
    "    'Model': ['Linear Regression', 'Polynomial Regression', 'KNN Regression', 'Random Forest Regression', 'SVR'],\n",
    "    'Test RMSE': [test_rmse, test_errors[np.argmin(test_errors)], test_rmse_knr, test_rmse_rfr, test_rmse_svr],\n",
    "    'Test R²': [test_r2, test_r2_scores[np.argmax(test_r2_scores)], test_r2_knr, test_r2_rfr, test_r2_svr]\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table of results\n",
    "results_summary = {\n",
    "    'Model': ['Linear Regression', \n",
    "              f'Polynomial Regression (Degree {best_degree})', \n",
    "              'KNN Regression', \n",
    "              'Random Forest Regression', \n",
    "              'Support Vector Regression'],\n",
    "    'Test RMSE': [test_rmse, \n",
    "                  test_errors[np.argmin(test_errors)], \n",
    "                  test_rmse_knr, \n",
    "                  test_rmse_rfr, \n",
    "                  test_rmse_svr],\n",
    "    'Test R²': [test_r2, \n",
    "                test_r2_scores[np.argmax(test_r2_scores)], \n",
    "                test_r2_knr, \n",
    "                test_r2_rfr, \n",
    "                test_r2_svr]\n",
    "}\n",
    "\n",
    "# Convert to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(results_df)\n",
    "\n",
    "# Alternatively, display the table in Markdown format\n",
    "from IPython.display import Markdown\n",
    "\n",
    "markdown_table = \"\"\"\n",
    "| **Model**                  | **Test RMSE** | **Test R²** |\n",
    "|----------------------------|---------------|-------------|\n",
    "| Linear Regression          | {lr_rmse}     | {lr_r2}     |\n",
    "| Polynomial Regression (Degree {best_degree}) | {poly_rmse} | {poly_r2} |\n",
    "| KNN Regression             | {knn_rmse}    | {knn_r2}    |\n",
    "| Random Forest Regression   | {rf_rmse}     | {rf_r2}     |\n",
    "| Support Vector Regression  | {svr_rmse}    | {svr_r2}    |\n",
    "\"\"\".format(\n",
    "    lr_rmse=test_rmse,\n",
    "    lr_r2=test_r2,\n",
    "    best_degree=best_degree,\n",
    "    poly_rmse=test_errors[np.argmin(test_errors)],\n",
    "    poly_r2=test_r2_scores[np.argmax(test_r2_scores)],\n",
    "    knn_rmse=test_rmse_knr,\n",
    "    knn_r2=test_r2_knr,\n",
    "    rf_rmse=test_rmse_rfr,\n",
    "    rf_r2=test_r2_rfr,\n",
    "    svr_rmse=test_rmse_svr,\n",
    "    svr_r2=test_r2_svr\n",
    ")\n",
    "\n",
    "display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "Based on the results, the **Random Forest Regression** model performs the best for salary prediction, with the lowest RMSE (**{test_rmse_rfr}**) and highest R² score (**{test_r2_rfr}**). This model is recommended for future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Model**                  | **Test RMSE** | **Test R²** |\n",
    "|----------------------------|---------------|-------------|\n",
    "| Linear Regression          | 22647.75      | 0.813       |\n",
    "| Polynomial Regression      | 19210.03      | 0.866       |\n",
    "| KNN Regression             | 15689.04      | 0.910       |\n",
    "| Random Forest Regression   | 12157.69      | 0.946       |\n",
    "| Support Vector Regression  | 30956.66      | 0.651       |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
